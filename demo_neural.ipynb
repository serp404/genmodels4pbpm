{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce77f1b",
   "metadata": {
    "cellId": "9mgmidtdgho1bdhbolgrq4"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c67056",
   "metadata": {
    "cellId": "hu8i0jvb4o34e7d77f0qv"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pm4py\n",
    "import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.cuda.manual_seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7db95c",
   "metadata": {
    "cellId": "lsa5e9jvk92atddk2ey3v"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "LOG_TYPE = 'bpi12'\n",
    "event_log = pm4py.objects.log.importer.xes.importer.apply(f'./data/{LOG_TYPE}.xes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff10fe8",
   "metadata": {
    "cellId": "5sbp129b0jmq8g0psht29"
   },
   "source": [
    "# Logs cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c35974",
   "metadata": {
    "cellId": "d143ofv2dybmegmx8sm2n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.datasets import filter_log\n",
    "\n",
    "event_log_filtered = filter_log(event_log, LOG_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb6d89b",
   "metadata": {
    "cellId": "ksjq8ilybtn1foyytl0kkr"
   },
   "source": [
    "### Define mapping from activity name to activity id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad454638",
   "metadata": {
    "cellId": "ct45z7v1wjqohe15gt5h2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "act2id = {'<PAD>': 0, '<BOS>': 1, '<EOS>': 2}\n",
    "id2act = {0: '<PAD>', 1: '<BOS>', 2: '<EOS>'}\n",
    "\n",
    "current_id = 3\n",
    "for t in event_log_filtered:\n",
    "    for e in t:\n",
    "        if e['concept:name'] not in act2id:\n",
    "            act2id[e['concept:name']] = current_id\n",
    "            id2act[current_id] = e['concept:name']\n",
    "            current_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b977fb01",
   "metadata": {
    "cellId": "4z20ekrknv3lmafmxzcrlh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.utils import uniform_kl\n",
    "\n",
    "# new frequencies\n",
    "activities = {}\n",
    "for t in event_log_filtered:\n",
    "    for e in t:\n",
    "        activities[act2id[e['concept:name']]] = activities.get(act2id[e['concept:name']], 0) + 1\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "print(activities)\n",
    "sns.barplot(\n",
    "    x=[p[0] for p in activities.items()],\n",
    "    y=[p[1] for p in activities.items()]\n",
    ").grid()\n",
    "\n",
    "initial_probs = np.array([val for _, val in activities.items()]) / sum(val for _, val in activities.items())\n",
    "print(f\"Initial uniformed KL: {uniform_kl(initial_probs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f2cc8",
   "metadata": {
    "cellId": "tjkm2jh3hxsugwdcg0huh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.utils import time_aware_data_split\n",
    "\n",
    "train_log, val_log, test_log = time_aware_data_split(event_log_filtered, (0.7, 0.1, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e16dd3",
   "metadata": {
    "cellId": "l9oijgpugdhd0kb4mggggs"
   },
   "source": [
    "# Log datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c780b47f",
   "metadata": {
    "cellId": "af7ay220swr011mquep1hzt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.datasets import LogsDataset\n",
    "\n",
    "normalizer_value = np.percentile(\n",
    "    [np.max(np.diff([t[i]['time:timestamp'].timestamp() for i in range(len(t))]))\n",
    "         for t in event_log_filtered], q=90\n",
    ")\n",
    "\n",
    "def time_scaling(time: float) -> float:\n",
    "    return time / normalizer_value\n",
    "\n",
    "def invert_scaling(scaled_time: float) -> float:\n",
    "    return scaled_time * normalizer_value\n",
    "\n",
    "train_ds = LogsDataset(train_log, act2id, time_applyer=time_scaling)\n",
    "val_ds = LogsDataset(val_log, act2id, time_applyer=time_scaling)\n",
    "test_ds = LogsDataset(test_log, act2id, time_applyer=time_scaling)\n",
    "\n",
    "print(f'Normalizer value: {normalizer_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe32354",
   "metadata": {
    "cellId": "1n2v0c3kuqarx2wijmmg3f"
   },
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed46f6",
   "metadata": {},
   "source": [
    "## Augmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866eb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.models import LogVAE\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LogVAE(\n",
    "    n_features=27, latent_dim=256, num_classes=26,\n",
    "    emb_dim=64, hid_dim=128, num_layers=3, bidirectional=True\n",
    ").to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load('./checkpoints/vae_bpi12/model_best.pth', map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533ee803",
   "metadata": {},
   "source": [
    "## Augmentation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05af5382",
   "metadata": {
    "cellId": "1g1smzlfzfk1oncx0hu5j"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.augmentations import NeuralAugmentation\n",
    "\n",
    "aug = NeuralAugmentation(model, act2id, sample_size=5000).fit(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb805d",
   "metadata": {
    "cellId": "bt5v8ob43292sdkvvumd9x"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# rare_act_ids = [15, 16, 17, 18, 21, 23, 25]\n",
    "rare_act_ids = [21, 22, 24, 25, 26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcc96b",
   "metadata": {
    "cellId": "j7vbokzao09fdvker2ev7j"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "synthetic_traces = []\n",
    "for act_id in rare_act_ids:\n",
    "    synthetic_traces.extend(aug.sample([act_id], n_iters=1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1444cd68",
   "metadata": {
    "cellId": "l63xab8ua9qbnz3tkyuktd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "activities = {}\n",
    "for t in synthetic_traces:\n",
    "    for e in t:\n",
    "        activities[e[0]] = activities.get(e[0], 0) + 1\n",
    "\n",
    "for t in event_log_filtered:\n",
    "    for e in t:\n",
    "        activities[act2id[e['concept:name']]] = activities.get(act2id[e['concept:name']], 0) + 1\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "print(activities)\n",
    "sns.barplot(\n",
    "    x=[p[0] for p in activities.items()],\n",
    "    y=[p[1] for p in activities.items()]\n",
    ").grid()\n",
    "\n",
    "final_probs = np.array([val for _, val in activities.items()]) / sum(val for _, val in activities.items())\n",
    "print(f\"Final uniformed KL: {uniform_kl(final_probs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8df36",
   "metadata": {
    "cellId": "8qgvv3n4ayyfn1jao6usd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from copy import deepcopy\n",
    "\n",
    "train_ds.extend_log(synthetic_traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83794a04",
   "metadata": {
    "cellId": "8ghyvyre4cpmeay9l5abqe"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb758db",
   "metadata": {
    "cellId": "mddpw8re99vje50e4ai39"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.utils import prediction_collate_fn\n",
    "from logmentations.datasets import SlicedLogsDataset\n",
    "from logmentations.datasets import LengthAwareSampler\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "sliced_train_ds = SlicedLogsDataset(train_ds)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=sliced_train_ds,\n",
    "    batch_sampler=LengthAwareSampler(\n",
    "        data_len=len(sliced_train_ds),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        group_size=BATCH_SIZE * 16\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    collate_fn=prediction_collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=SlicedLogsDataset(val_ds),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=prediction_collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    SlicedLogsDataset(test_ds),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=prediction_collate_fn,\n",
    "    pin_memory=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f695d7",
   "metadata": {
    "cellId": "ry8lzusbqdlphvc1mem0j"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc76f3e",
   "metadata": {
    "cellId": "p64f3apicgq7arbwjesup6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.models import LstmModel\n",
    "from logmentations.training import BaseConfig, train_predictive_epoch, eval_predictive_model\n",
    "\n",
    "model = LstmModel(\n",
    "    vocab_size=26, n_features=27,\n",
    "    emb_size=64, hid_size=128,\n",
    "    num_layers=3, bidirectional=True,\n",
    "    predict_time=True\n",
    ").to(DEVICE)\n",
    "\n",
    "N_EPOCHS = 100\n",
    "SAVE_PERIOD = 25\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=N_EPOCHS)\n",
    "act_weight, time_weight = 1., 0.8\n",
    "\n",
    "CONFIG = BaseConfig({\n",
    "    \"n_epochs\": N_EPOCHS,\n",
    "    \"save_period\": SAVE_PERIOD,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"scheduler\": scheduler,\n",
    "    \"grad_clip_value\": 5.,\n",
    "    \"act_weight\": 1.,\n",
    "    \"time_weight\": 0.8,\n",
    "    \"device\": DEVICE\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687ec67",
   "metadata": {
    "cellId": "2hv0gs8mo57lxp8vgpcsrr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "run = wandb.init(\n",
    "    project=\"GenModels4PBPM-Prediction\",\n",
    "    entity=\"serp404\",\n",
    "    tags=[\"prediction\", \"nn_aug_data\", LOG_TYPE]\n",
    ")\n",
    "\n",
    "save_path = os.path.join(\"./checkpoints\", run.name)\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "best_f1 = None\n",
    "for epoch in tqdm.notebook.tqdm(range(N_EPOCHS), \"Training\"):\n",
    "    # Train step\n",
    "    train_loss, train_ce, train_mae, grad_norm = train_predictive_epoch(\n",
    "        model, train_loader, CONFIG\n",
    "    )\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation step\n",
    "    val_loss, val_ce, val_mae, val_accuracy, val_f1_macro = eval_predictive_model(\n",
    "        model, val_loader, CONFIG\n",
    "    )\n",
    "\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_ce\": train_ce,\n",
    "            \"train_mae\": train_mae,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_ce\": val_ce,\n",
    "            \"val_mae\": val_mae,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_f1_macro_score\": val_f1_macro,\n",
    "            \"grad_norm\": grad_norm,\n",
    "            \"lr\": optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if best_f1 is None or val_f1_macro > best_f1:\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            os.path.join(save_path, f\"model_best.pth\")\n",
    "        )\n",
    "        best_f1 = val_f1_macro\n",
    "\n",
    "    if epoch % SAVE_PERIOD == 0:\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            os.path.join(save_path, f\"model_e{epoch}.pth\")\n",
    "        )\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6e6e0",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from logmentations.models import LstmModel\n",
    "from logmentations.training import eval_prediction_test_metrics\n",
    "\n",
    "# Test step\n",
    "model_best = LstmModel(\n",
    "    vocab_size=26, n_features=27,\n",
    "    emb_size=64, hid_size=128,\n",
    "    num_layers=3, bidirectional=True,\n",
    "    predict_time=True\n",
    ").to(DEVICE)\n",
    "\n",
    "model_best.load_state_dict(torch.load(os.path.join(save_path, \"model_best.pth\"), map_location=DEVICE))\n",
    "\n",
    "def time2days(time: float) -> float:\n",
    "    return invert_scaling(time) / 3600 / 24\n",
    "\n",
    "N_RUNS = 20\n",
    "loss, ce, inv_mae, accuracy, f1 = eval_prediction_test_metrics(\n",
    "    model_best, test_loader, CONFIG_BASE,\n",
    "    time2days=time2days, n_runs=N_RUNS\n",
    ")\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Loss CE: {ce}')\n",
    "print(f'Loss MAE: {inv_mae}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1-macro: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721cf80b",
   "metadata": {
    "cellId": "ens5gvwlijqx7lsx0yx59"
   },
   "outputs": [],
   "source": [
    "#!g1.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "notebookId": "cef313ef-950b-488e-ac73-dcc37438083a",
  "notebookPath": "genmodels4pbpm-main/demo_statistics.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
